# Spark

## What is Spark?

The official [https://spark.apache.org/](Apache Spark) site greets you with

> Apache Spark is a multi-language engine for executing data engineering, data science, and machine learning on single-node machines or clusters.

In Learning Spark, the authors define Spark as:

> Apache Spark is a unified engine designed for large-scale distributed data processing, on premises in data centers or in the cloud.

Between these two definitions, I would add Spark is the modern solution to
large-scale data operations.

## Why Spark?

* Spark is widely available across popular languages (Python, Scala, Java,
  etc.)
* Spark focuses on: speed, ease of use, modularity, extensibility
* Spark has libraries built on top its core function for machine learning
  (MLlib), interactive SQL (Spark SQL), stream processing (Structured
  Streaming), and graph processing (GraphX)

## Resources Used

* [Taming Big Data with Apache Spark](https://www.udemy.com/course/taming-big-data-with-apache-spark-hands-on/)
* [Learning Spark: Lightning-Fast Data Analytics [2nd Edition]](https://learning.oreilly.com/library/view/learning-spark-2nd/9781492050032/)
* [Data Engineering using AWS Data Analytics](https://www.udemy.com/course/data-engineering-using-aws-analytics-services/)
